{
  "profession": "data-scientist",
  "language": "es",
  "categories": [
    {
      "id": "interview-questions",
      "name": "Preguntas de Entrevista",
      "count": 156,
      "icon": "üí¨",
      "color": "bg-blue-100 text-blue-800"
    },
    {
      "id": "technical-tasks",
      "name": "Tareas T√©cnicas",
      "count": 89,
      "icon": "‚ö°",
      "color": "bg-green-100 text-green-800"
    },
    {
      "id": "system-design",
      "name": "Dise√±o de Sistemas",
      "count": 45,
      "icon": "üèóÔ∏è",
      "color": "bg-purple-100 text-purple-800"
    },
    {
      "id": "behavioral",
      "name": "Preguntas Conductuales",
      "count": 67,
      "icon": "üß†",
      "color": "bg-orange-100 text-orange-800"
    },
    {
      "id": "algorithms",
      "name": "Algoritmos y Estructuras de Datos",
      "count": 123,
      "icon": "üìä",
      "color": "bg-red-100 text-red-800"
    },
    {
      "id": "best-practices",
      "name": "Mejores Pr√°cticas",
      "count": 78,
      "icon": "‚≠ê",
      "color": "bg-yellow-100 text-yellow-800"
    }
  ],
  "materials": [
    {
      "id": 1,
      "title": "Aprendizaje Autom√°tico: De B√°sico a Algoritmos Avanzados",
      "description": "Gu√≠a completa de aprendizaje autom√°tico con ejemplos pr√°cticos",
      "category": "interview-questions",
      "difficulty": "advanced",
      "readTime": 30,
      "rating": 4.9,
      "reads": 1345,
      "tags": ["Aprendizaje Autom√°tico", "Python", "Scikit-learn", "Algoritmos"],
      "content": "# Aprendizaje Autom√°tico: De B√°sico a Algoritmos Avanzados\n\n## Aprendizaje Supervisado\n\n```python\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\n# Preparaci√≥n de datos\nX = df[['caracteristica1', 'caracteristica2', 'caracteristica3']]\ny = df['objetivo']\n\n# Divisi√≥n de datos\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# Entrenamiento del modelo\nmodelo = RandomForestClassifier(n_estimators=100, random_state=42)\nmodelo.fit(X_train, y_train)\n\n# Predicciones\ny_pred = modelo.predict(X_test)\nprint(classification_report(y_test, y_pred))\n```\n\n## Aprendizaje Profundo\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\n\n# Crear modelo\nmodelo = Sequential([\n    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n    Dropout(0.3),\n    Dense(64, activation='relu'),\n    Dense(1, activation='sigmoid')\n])\n\n# Compilar\nmodelo.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Entrenar\nhistoria = modelo.fit(X_train, y_train, epochs=50, validation_split=0.2)\n```\n\n## Ingenier√≠a de Caracter√≠sticas\n\n```python\n# Crear nuevas caracter√≠sticas\ndf['ratio_caracteristica'] = df['caracteristica1'] / df['caracteristica2']\ndf['suma_caracteristica'] = df['caracteristica1'] + df['caracteristica2']\n\n# Caracter√≠sticas polinomiales\nfrom sklearn.preprocessing import PolynomialFeatures\npoly = PolynomialFeatures(degree=2, include_bias=False)\nX_poly = poly.fit_transform(X_scaled)\n```\n\n## Validaci√≥n de Modelos\n\n```python\nfrom sklearn.model_selection import cross_val_score\n\n# Validaci√≥n cruzada\ncv_scores = cross_val_score(modelo, X, y, cv=5, scoring='accuracy')\nprint(f'Puntuaci√≥n CV media: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})')\n```\n\n## Conclusi√≥n\n\nEl aprendizaje autom√°tico requiere comprensi√≥n profunda de algoritmos, habilidades de manipulaci√≥n de datos y aprendizaje continuo de nuevos m√©todos.",
      "isNew": false,
      "isPopular": true,
      "createdAt": "2024-01-01T00:00:00Z"
    },
    {
      "id": 2,
      "title": "Aprendizaje Profundo con TensorFlow y PyTorch",
      "description": "Gu√≠a pr√°ctica de aprendizaje profundo",
      "category": "technical-tasks",
      "difficulty": "advanced",
      "readTime": 25,
      "rating": 4.8,
      "reads": 987,
      "tags": ["Aprendizaje Profundo", "TensorFlow", "PyTorch", "Redes Neuronales"],
      "content": "# Aprendizaje Profundo con TensorFlow y PyTorch\n\n## TensorFlow\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n\n# API Funcional\ninputs = tf.keras.Input(shape=(784,))\nx = layers.Dense(128, activation='relu')(inputs)\nx = layers.Dropout(0.2)(x)\noutputs = layers.Dense(10, activation='softmax')(x)\n\nmodelo = tf.keras.Model(inputs=inputs, outputs=outputs)\nmodelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n```\n\n## PyTorch\n\n```python\nimport torch\nimport torch.nn as nn\n\nclass RedNeuronal(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super().__init__()\n        self.capa1 = nn.Linear(input_size, hidden_size)\n        self.capa2 = nn.Linear(hidden_size, output_size)\n        self.relu = nn.ReLU()\n    \n    def forward(self, x):\n        x = self.relu(self.capa1(x))\n        x = self.capa2(x)\n        return x\n\nmodelo = RedNeuronal(784, 128, 10)\ncriterio = nn.CrossEntropyLoss()\noptimizador = torch.optim.Adam(modelo.parameters())\n```\n\n## Conclusi√≥n\n\nEl aprendizaje profundo abre nuevas posibilidades para resolver problemas complejos pero requiere recursos computacionales significativos.",
      "isNew": true,
      "isPopular": true,
      "createdAt": "2024-01-15T00:00:00Z"
    },
    {
      "id": 3,
      "title": "Procesamiento de Lenguaje Natural (NLP)",
      "description": "M√©todos modernos de procesamiento de texto y modelos de lenguaje",
      "category": "best-practices",
      "difficulty": "advanced",
      "readTime": 22,
      "rating": 4.7,
      "reads": 756,
      "tags": ["NLP", "BERT", "Transformers", "Tokenizaci√≥n"],
      "content": "# Procesamiento de Lenguaje Natural (NLP)\n\n## Transformers\n\n```python\nfrom transformers import AutoTokenizer, AutoModel\nimport torch\n\n# Cargar modelo pre-entrenado\nmodelo_nombre = 'bert-base-uncased'\ntokenizer = AutoTokenizer.from_pretrained(modelo_nombre)\nmodelo = AutoModel.from_pretrained(modelo_nombre)\n\n# Tokenizar texto\ntexto = \"Hola, ¬øc√≥mo est√°s?\"\ninputs = tokenizer(texto, return_tensors=\"pt\", padding=True, truncation=True)\n\n# Obtener embeddings\nwith torch.no_grad():\n    outputs = modelo(**inputs)\n    embeddings = outputs.last_hidden_state\n```\n\n## Fine-tuning\n\n```python\nfrom transformers import Trainer, TrainingArguments\n\n# Argumentos de entrenamiento\ntraining_args = TrainingArguments(\n    output_dir='./resultados',\n    num_train_epochs=3,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=64,\n    warmup_steps=500,\n    weight_decay=0.01,\n)\n\n# Entrenar\ntrainer = Trainer(model=modelo, args=training_args, train_dataset=dataset_entrenamiento)\ntrainer.train()\n```\n\n## Conclusi√≥n\n\nNLP est√° evolucionando r√°pidamente gracias a los transformers y modelos de lenguaje grandes. Es importante mantenerse actualizado con nuevos desarrollos.",
      "isNew": true,
      "isPopular": false,
      "createdAt": "2024-01-20T00:00:00Z"
    }
  ]
}
